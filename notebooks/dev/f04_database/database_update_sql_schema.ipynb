{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database: Cleaning tables, views, schema  (draft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(postgresql://manuel:***@5.75.190.71:6947/fairicube)\n",
      "Enngine loaded --- next steps can be started!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as x\n",
    "from configparser import ConfigParser\n",
    "import sqlalchemy as sa # conection to the database\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "### SET conection to MS-sql server:\n",
    "################################################## SET postgre-sql connection:\n",
    "\n",
    "################################################## read database keys:\n",
    "def config(filename, section='postgresql'):\n",
    "    # create a parser\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(filename)\n",
    "\n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception(\n",
    "            'Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    return db\n",
    "\n",
    "keys = config(filename='database.ini')\n",
    "\n",
    "POSTGRESQL_SERVER_NAME=keys['host']\n",
    "PORT=                  keys['port']\n",
    "Database_name =        keys['database']\n",
    "USER =                 keys['user']\n",
    "PSW =                  keys['password']\n",
    "##################################################\n",
    "\n",
    "engine_postgresql = sa.create_engine('postgresql://'+USER+':'+PSW+ '@'+POSTGRESQL_SERVER_NAME+':'+str(PORT)+ '/' + Database_name)\n",
    "print (engine_postgresql)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"Enngine loaded --- next steps can be started!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.1) Removing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 -removing of table - done\n"
     ]
    }
   ],
   "source": [
    "## (1.1) Removing table - if Exists:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_urban_atlas_test\"\n",
    "\n",
    "## removing table:...........................................S\n",
    "#query_drop = (\"\"\"DROP TABLE IF EXISTS cube.c_city_eurostat_de1028i_test  ;\"\"\")\n",
    "query_drop = (\"DROP TABLE IF EXISTS \"+schema+\".\"+name_of_table+\";\")             \n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_drop)\n",
    "connection.commit()\n",
    "## removing table:...........................................E\n",
    "\n",
    "print (\"1.1 -removing of table - done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.2) UNION TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Add new columns:\n",
      "      \n",
      "        CREATE TABLE cube.cu_city_dem\n",
      "        AS\n",
      "\n",
      "                SELECT * From cube.cu_city_dem_std\n",
      "              UNION\n",
      "                SELECT * From cube.cu_city_dem_max\n",
      "              UNION\n",
      "                SELECT * From cube.cu_city_dem_mean\n",
      "              UNION\n",
      "                SELECT * From cube.cu_city_dem_min\n",
      "              UNION\n",
      "                SELECT * From cube.cu_city_dem_std\n",
      "         \n",
      "            \n",
      "         \n",
      "union done!°!\n"
     ]
    }
   ],
   "source": [
    "## (1.2) UNION table :\n",
    "\n",
    "\n",
    "## example:\n",
    "#schema = \"cube\"\n",
    "#name_of_table = \"cu_city_dem\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "\n",
    "query_union_to_new_table = (\"\"\"      \n",
    "        CREATE TABLE cube.cu_city_dem\n",
    "        AS\n",
    "\n",
    "                SELECT * From cube.cu_city_dem_std\n",
    "              UNION\n",
    "                SELECT * From cube.cu_city_dem_max\n",
    "              UNION\n",
    "                SELECT * From cube.cu_city_dem_mean\n",
    "              UNION\n",
    "                SELECT * From cube.cu_city_dem_min\n",
    "              UNION\n",
    "                SELECT * From cube.cu_city_dem_std\n",
    "         \n",
    "            \n",
    "         \"\"\")\n",
    "\n",
    "print (query_union_to_new_table)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_union_to_new_table)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "print (\"union done!°!\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.1) Adding missing metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Add new columns:\n",
      "\n",
      "         \n",
      "ALTER TABLE cube.cu_urban_atlas_test \n",
      "--ADD COLUMN city_code VARCHAR,\n",
      "--ADD COLUMN city_code_version VARCHAR,\n",
      "--ADD COLUMN parameter VARCHAR,\n",
      "--ADD COLUMN parameter_value FLOAT,\n",
      "ADD COLUMN lineage TEXT,\n",
      "ADD COLUMN datasource VARCHAR;\n",
      "         \n",
      "            \n",
      "         \n",
      "B) update new columns:\n",
      "\n",
      "         \n",
      "UPDATE cube.cu_urban_atlas_test \n",
      "SET\n",
      "-- city_code ='xx001c1xx',\n",
      "-- city_code_version ='ua_2021',\n",
      "-- parameter = '\"Number days..blabla..',\n",
      "-- parameter_value = -999,\n",
      " lineage   = 'blablablablabla',\n",
      " datasource ='xxEurostat....';\n",
      "         \n",
      "            \n",
      "         \n",
      "update of table done!\n"
     ]
    }
   ],
   "source": [
    "## (2.1) Adding missing metadata.\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_urban_atlas_test\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "query_new_columns = (\"\"\"\n",
    "         \n",
    "ALTER TABLE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "--ADD COLUMN city_code VARCHAR,\n",
    "--ADD COLUMN city_code_version VARCHAR,\n",
    "--ADD COLUMN parameter VARCHAR,\n",
    "--ADD COLUMN parameter_value FLOAT,\n",
    "ADD COLUMN lineage TEXT,\n",
    "ADD COLUMN datasource VARCHAR;\n",
    "         \n",
    "            \n",
    "         \"\"\")\n",
    "\n",
    "print (query_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "################ update columns:\n",
    "print (\"B) update new columns:\")\n",
    "query_update_new_columns = (\"\"\"\n",
    "         \n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "SET\n",
    "-- city_code ='xx001c1xx',\n",
    "-- city_code_version ='ua_2021',\n",
    "-- parameter = '\"Number days..blabla..',\n",
    "-- parameter_value = -999,\n",
    " lineage   = 'blablablablabla',\n",
    " datasource ='xxEurostat....';\n",
    "         \n",
    "            \n",
    "         \"\"\")\n",
    "print (query_update_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_update_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "print (\"update of table done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.1) Transform tables (pivot, columns to rows ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation ob table:\n",
      "        estat_code urau_code city_code city_code_version  \\\n",
      "0               AT   DE1028I        AT           ua_2021   \n",
      "1               AT   DE1055i        AT           ua_2021   \n",
      "2           AT001C   DE1028I    AT001C           ua_2021   \n",
      "3           AT001C   DE1055i    AT001C           ua_2021   \n",
      "4           AT002C   DE1028I    AT002C           ua_2021   \n",
      "...            ...       ...       ...               ...   \n",
      "1534433     UK133C   DE1055i    UK133C           ua_2021   \n",
      "1534434     UK134C   DE1028I    UK134C           ua_2021   \n",
      "1534435     UK134C   DE1055i    UK134C           ua_2021   \n",
      "1534436     UK135C   DE1028I    UK135C           ua_2021   \n",
      "1534437     UK135C   DE1055i    UK135C           ua_2021   \n",
      "\n",
      "                                           parameter  \\\n",
      "0        \"Urban Audit indicators - check estat code\"   \n",
      "1        \"Urban Audit indicators - check estat code\"   \n",
      "2        \"Urban Audit indicators - check estat code\"   \n",
      "3        \"Urban Audit indicators - check estat code\"   \n",
      "4        \"Urban Audit indicators - check estat code\"   \n",
      "...                                              ...   \n",
      "1534433  \"Urban Audit indicators - check estat code\"   \n",
      "1534434  \"Urban Audit indicators - check estat code\"   \n",
      "1534435  \"Urban Audit indicators - check estat code\"   \n",
      "1534436  \"Urban Audit indicators - check estat code\"   \n",
      "1534437  \"Urban Audit indicators - check estat code\"   \n",
      "\n",
      "                                                   lineage  \\\n",
      "0        \"Data on European cities were collected in the...   \n",
      "1        \"Data on European cities were collected in the...   \n",
      "2        \"Data on European cities were collected in the...   \n",
      "3        \"Data on European cities were collected in the...   \n",
      "4        \"Data on European cities were collected in the...   \n",
      "...                                                    ...   \n",
      "1534433  \"Data on European cities were collected in the...   \n",
      "1534434  \"Data on European cities were collected in the...   \n",
      "1534435  \"Data on European cities were collected in the...   \n",
      "1534436  \"Data on European cities were collected in the...   \n",
      "1534437  \"Data on European cities were collected in the...   \n",
      "\n",
      "                                                datasource  year  \\\n",
      "0        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "1        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "2        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "3        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "4        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "...                                                    ...   ...   \n",
      "1534433  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "1534434  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "1534435  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "1534436  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "1534437  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "\n",
      "         parameter_value  \n",
      "0               8.094399  \n",
      "1               6.816773  \n",
      "2               9.061868  \n",
      "3               8.785802  \n",
      "4               9.533661  \n",
      "...                  ...  \n",
      "1534433              NaN  \n",
      "1534434              NaN  \n",
      "1534435              NaN  \n",
      "1534436              NaN  \n",
      "1534437              NaN  \n",
      "\n",
      "[1534438 rows x 9 columns]\n",
      "dataframe to sql:\n",
      "end transformation\n"
     ]
    }
   ],
   "source": [
    "## bring sql table to data frame:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_city_eurostat_new\"\n",
    "\n",
    "\n",
    "## open connection:\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "connection.commit()\n",
    "## testing reading tables from database:\n",
    "\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query_wide_table = text(\"\"\"\n",
    "    \n",
    "      SELECT estat_code, urau_code, \"1991\", \"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", city_code, city_code_version, parameter, lineage, datasource\n",
    "\tFROM cube.c_city_eurostat;\n",
    "    \n",
    "    \n",
    "    \"\"\")\n",
    "    df_wide_table = pd.read_sql_query(query_wide_table, conn)\n",
    "    \n",
    "    \n",
    "#print (df_wide_table)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Transformation ob table:\")\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "df_transformed_table =df_wide_table.melt(id_vars=[\n",
    "                    'estat_code', \n",
    "                    'urau_code', \n",
    "                    'city_code', \n",
    "                    'city_code_version', \n",
    "                    'parameter', \n",
    "                    'lineage', \n",
    "                    'datasource'\n",
    "                        ], var_name=\"year\", value_name=\"parameter_value\")\n",
    "\n",
    "\n",
    "\n",
    "print(df_transformed_table)\n",
    "\n",
    "\n",
    "\n",
    "print (\"dataframe to sql:\")\n",
    "\n",
    "\n",
    "###################################################\n",
    "#name_of_table = name_of_table\n",
    "export_df_to_sql = df_transformed_table  # dataframe to be exported\n",
    "schmema_name = schema\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "print (\"end transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send table to SQL:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m schmema_name \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcube\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m###################################################\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mexport_df_to_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_of_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_postgresql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschmema_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2987\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2831\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2832\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2983\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   2984\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa:E501\u001b[39;00m\n\u001b[0;32m   2985\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 2987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2988\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2998\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:695\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    692\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    693\u001b[0m     )\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m    696\u001b[0m     frame,\n\u001b[0;32m    697\u001b[0m     name,\n\u001b[0;32m    698\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m    699\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    700\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m    701\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    702\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    703\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    704\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    705\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    707\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:1738\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1726\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m   1728\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[0;32m   1729\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   1730\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1736\u001b[0m )\n\u001b[1;32m-> 1738\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[0;32m   1739\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m   1740\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectable,\n\u001b[0;32m   1741\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   1742\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   1743\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   1744\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   1745\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   1746\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m   1748\u001b[0m )\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:1325\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mSQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(1054, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf(e0)?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield list\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m))(?#\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;124m    )|inf can not be used with MySQL\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:946\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    945\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[1;32m--> 946\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(num_inserted):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:853\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    852\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[1;32m--> 853\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1306\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1302\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[0;32m   1303\u001b[0m         exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[38;5;241m=\u001b[39merr\n\u001b[0;32m   1304\u001b[0m     )\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\elements.py:332\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    330\u001b[0m ):\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[1;32m--> 332\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1498\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[0;32m   1486\u001b[0m compiled_cache \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1488\u001b[0m )\n\u001b[0;32m   1490\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1491\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1492\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1497\u001b[0m )\n\u001b[1;32m-> 1498\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1512\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1513\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1517\u001b[0m         ret,\n\u001b[0;32m   1518\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2047\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2043\u001b[0m         util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[0;32m   2044\u001b[0m             sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[0;32m   2045\u001b[0m         )\n\u001b[0;32m   2046\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2047\u001b[0m         \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1799\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1797\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1798\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1799\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_executemany\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n\u001b[0;32m   1803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\psycopg2.py:953\u001b[0m, in \u001b[0;36mPGDialect_psycopg2.do_executemany\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    951\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    952\u001b[0m     xtras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_psycopg2_extras()\n\u001b[1;32m--> 953\u001b[0m     context\u001b[38;5;241m.\u001b[39m_psycopg2_fetched_rows \u001b[38;5;241m=\u001b[39m xtras\u001b[38;5;241m.\u001b[39mexecute_values(\n\u001b[0;32m    954\u001b[0m         cursor,\n\u001b[0;32m    955\u001b[0m         statement,\n\u001b[0;32m    956\u001b[0m         parameters,\n\u001b[0;32m    957\u001b[0m         template\u001b[38;5;241m=\u001b[39mexecutemany_values,\n\u001b[0;32m    958\u001b[0m         fetch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(context\u001b[38;5;241m.\u001b[39mcompiled\u001b[38;5;241m.\u001b[39mreturning),\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    960\u001b[0m     )\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_mode \u001b[38;5;241m&\u001b[39m EXECUTEMANY_BATCH:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_batch_page_size:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\psycopg2\\extras.py:1299\u001b[0m, in \u001b[0;36mexecute_values\u001b[1;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1298\u001b[0m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m post\n\u001b[1;32m-> 1299\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch:\n\u001b[0;32m   1301\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(cur\u001b[38;5;241m.\u001b[39mfetchall())\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print (\"send table to SQL:\")\n",
    "\n",
    "###################################################\n",
    "name_of_table = 'cu_test'\n",
    "export_df_to_sql = df_transformed_table  # dataframe to be exported\n",
    "schmema_name ='cube'\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "\n",
    "\n",
    "\n",
    "## close connection:\n",
    "#cursor.close()\n",
    "#connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.1) VIEW 1 ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3.1) Set up of VIEW\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_urban_atlas_test\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "query_view = (\"\"\"\n",
    "         \n",
    "-- View: cube.CITY_main_cube\n",
    "\n",
    "-- DROP VIEW cube.\"CITY_main_cube\";\n",
    "\n",
    "CREATE OR REPLACE VIEW cube.\"CITY_main_cube\"\n",
    " AS\n",
    "\n",
    " SELECT cu_city_drought.city_code,\n",
    "    cu_city_drought.city_code_version,\n",
    "    cu_city_drought.parameter,\n",
    "    cu_city_drought.parameter_id,\n",
    "    cu_city_drought.parameter_value,\n",
    "    cu_city_drought.year\n",
    "   FROM cube.cu_city_drought\n",
    "UNION\n",
    " SELECT cu_city_burnt_area_wild_fire.city_code,\n",
    "    cu_city_burnt_area_wild_fire.city_code_version,\n",
    "    cu_city_burnt_area_wild_fire.parameter,\n",
    "    cu_city_burnt_area_wild_fire.parameter_id,\n",
    "    cu_city_burnt_area_wild_fire.parameter_value,\n",
    "    cu_city_burnt_area_wild_fire.year\n",
    "   FROM cube.cu_city_burnt_area_wild_fire\n",
    "UNION\n",
    " SELECT cu_urban_atlas.city_code,\n",
    "    cu_urban_atlas.city_code_version,\n",
    "    cu_urban_atlas.parameter,\n",
    "    cu_urban_atlas.parameter_id,\n",
    "    cu_urban_atlas.parameter_value,\n",
    "    cu_urban_atlas.year\n",
    "   FROM cube.cu_urban_atlas\n",
    "UNION\n",
    " SELECT cu_city_eurostat.city_code,\n",
    "    cu_city_eurostat.city_code_version,\n",
    "    cu_city_eurostat.parameter,\n",
    "    cu_city_eurostat.parameter_id,\n",
    "    cu_city_eurostat.parameter_value,\n",
    "    cu_city_eurostat.year\n",
    "   FROM cube.cu_city_eurostat\n",
    "UNION\n",
    " SELECT cu_city_treecover.city_code,\n",
    "    cu_city_treecover.city_code_version,\n",
    "    cu_city_treecover.parameter,\n",
    "    cu_city_treecover.parameter_id,\n",
    "    cu_city_treecover.parameter_value,\n",
    "    cu_city_treecover.year\n",
    "   FROM cube.cu_city_treecover\n",
    "UNION\n",
    " SELECT cu_city_dem.city_code,\n",
    "    cu_city_dem.city_code_version,\n",
    "    cu_city_dem.parameter,\n",
    "    cu_city_dem.parameter_id,\n",
    "    cu_city_dem.parameter_value,\n",
    "    cu_city_dem.year\n",
    "   FROM cube.xxcu_city_dem_mean\n",
    "UNION\n",
    " SELECT cu_city_imperviousness_area.city_code,\n",
    "    cu_city_imperviousness_area.city_code_version,\n",
    "    cu_city_imperviousness_area.parameter,\n",
    "    cu_city_imperviousness_area.parameter_id,\n",
    "    cu_city_imperviousness_area.parameter_value,\n",
    "    cu_city_imperviousness_area.year\n",
    "   FROM cube.cu_city_imperviousness_area;\n",
    "     \n",
    "            \n",
    "         \"\"\")\n",
    "\n",
    "print (query_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_view)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Add new columns:\n",
      "\n",
      "         \n",
      "ALTER TABLE cube.c_city_eurostat_de1055i \n",
      "ADD COLUMN city_code VARCHAR,\n",
      "ADD COLUMN city_code_version VARCHAR,\n",
      "ADD COLUMN parameter VARCHAR,\n",
      "--ADD COLUMN parameter_id VARCHAR\n",
      "---ADD COLUMN parameter_value FLOAT,\n",
      "ADD COLUMN lineage TEXT,\n",
      "ADD COLUMN datasource VARCHAR;        \n",
      "         \n",
      "B) update new columns:\n",
      "\n",
      "         \n",
      "UPDATE cube.c_city_eurostat_de1055i \n",
      "SET\n",
      "city_code = urau_code,\n",
      "city_code_version ='ua_2021',\n",
      "parameter = '\"Urban Audit indicators - check estat code\"',\n",
      "--parameter_value = parameter_value/10000.00 ,\n",
      " --parameter_id = 'city_copernicus_dem',\n",
      " lineage   = '\"Data on European cities were collected in the Urban Audit and in the Large City Audit project - for more information open the datasource\"',\n",
      " datasource ='\"https://ec.europa.eu/eurostat/cache/metadata/en/urb_esms.htm\"';\n",
      "         \n",
      "            \n",
      "         \n",
      "update of table done!\n"
     ]
    }
   ],
   "source": [
    "## (2.1) Adding missing metadata.\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table =  \"c_city_eurostat_de1055i\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "query_new_columns = (\"\"\"\n",
    "         \n",
    "ALTER TABLE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "ADD COLUMN city_code VARCHAR,\n",
    "ADD COLUMN city_code_version VARCHAR,\n",
    "ADD COLUMN parameter VARCHAR,\n",
    "--ADD COLUMN parameter_id VARCHAR\n",
    "---ADD COLUMN parameter_value FLOAT,\n",
    "ADD COLUMN lineage TEXT,\n",
    "ADD COLUMN datasource VARCHAR;        \n",
    "         \"\"\")\n",
    "\n",
    "print (query_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "################ update columns:\n",
    "print (\"B) update new columns:\")\n",
    "query_update_new_columns = (\"\"\"\n",
    "         \n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "SET\n",
    "city_code = urau_code,\n",
    "city_code_version ='ua_2021',\n",
    "parameter = '\"Urban Audit indicators - check estat code\"',\n",
    "--parameter_value = parameter_value/10000.00 ,\n",
    " --parameter_id = 'city_copernicus_dem',\n",
    " lineage   = '\"Data on European cities were collected in the Urban Audit and in the Large City Audit project - for more information open the datasource\"',\n",
    " datasource ='\"https://ec.europa.eu/eurostat/cache/metadata/en/urb_esms.htm\"';\n",
    "         \n",
    "            \n",
    "         \"\"\")\n",
    "print (query_update_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_update_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "print (\"update of table done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
