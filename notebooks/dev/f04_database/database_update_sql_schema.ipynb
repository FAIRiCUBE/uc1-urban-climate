{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database: Cleaning tables, views, schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(postgresql://manuel:***@5.75.190.71:6947/fairicube)\n",
      "Enngine loaded --- next steps can be started!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.db_connect import create_engine\n",
    "from sqlalchemy import text\n",
    "\n",
    "################################################## SET postgre-sql connection:\n",
    "engine_postgresql = create_engine('path/to/database.ini')\n",
    "print (\"Engine started..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.1) Removing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 -removing of table - done\n"
     ]
    }
   ],
   "source": [
    "## (1.1) Removing table - if Exists:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_urban_atlas_test\"\n",
    "\n",
    "## removing table:...........................................S\n",
    "#query_drop = (\"\"\"DROP TABLE IF EXISTS cube.c_city_eurostat_de1028i_test  ;\"\"\")\n",
    "query_drop = (\"DROP TABLE IF EXISTS \"+schema+\".\"+name_of_table+\";\")             \n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_drop)\n",
    "connection.commit()\n",
    "## removing table:...........................................E\n",
    "\n",
    "print (\"1.1 -removing of table - done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.2) UNION TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Add new columns:\n",
      "      \n",
      "        CREATE TABLE cube.cu_city_dem\n",
      "        AS\n",
      "\n",
      "                SELECT * From cube.cu_city_dem_std\n",
      "              UNION\n",
      "                SELECT * From cube.cu_city_dem_max\n",
      "              UNION\n",
      "                SELECT * From cube.cu_city_dem_mean\n",
      "              UNION\n",
      "                SELECT * From cube.cu_city_dem_min\n",
      "              UNION\n",
      "                SELECT * From cube.cu_city_dem_std\n",
      "         \n",
      "            \n",
      "         \n",
      "union done!Â°!\n"
     ]
    }
   ],
   "source": [
    "## (1.2) UNION table :\n",
    "\n",
    "\n",
    "## example:\n",
    "#schema = \"cube\"\n",
    "#name_of_table = \"cu_city_dem\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "\n",
    "query_union_to_new_table = (\"\"\"      \n",
    "        CREATE TABLE cube.cu_city_dem\n",
    "        AS\n",
    "                SELECT * From cube.cu_city_dem_std\n",
    "              UNION\n",
    "                SELECT * From cube.cu_city_dem_max\n",
    "              UNION\n",
    "                SELECT * From cube.cu_city_dem_mean\n",
    "              UNION\n",
    "                SELECT * From cube.cu_city_dem_min\n",
    "              UNION\n",
    "                SELECT * From cube.cu_city_dem_std\n",
    "         \"\"\")\n",
    "\n",
    "print (query_union_to_new_table)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_union_to_new_table)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.2) Get database -schema- overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get database overview\n",
      "   table_catalog table_schema                        table_name  table_type  \\\n",
      "0      fairicube         cube       c_city_burnt_area_wild_fire  BASE TABLE   \n",
      "1      fairicube         cube                    c_city_drought  BASE TABLE   \n",
      "2      fairicube         cube                  c_city_env_zones  BASE TABLE   \n",
      "3      fairicube         cube                   c_city_eurostat  BASE TABLE   \n",
      "4      fairicube         cube    c_city_hrl_imperviousness_2018  BASE TABLE   \n",
      "5      fairicube         cube         c_city_hrl_treecover_2018  BASE TABLE   \n",
      "6      fairicube         cube           c_city_urban_atlas_2012  BASE TABLE   \n",
      "7      fairicube         cube           c_city_urban_atlas_2018  BASE TABLE   \n",
      "8      fairicube         cube        c_city_water_classes_clc18  BASE TABLE   \n",
      "9      fairicube         cube                             c_dem  BASE TABLE   \n",
      "10     fairicube         cube                  c_utci_indicator  BASE TABLE   \n",
      "11     fairicube         cube      cu_city_burnt_area_wild_fire  BASE TABLE   \n",
      "12     fairicube         cube                       cu_city_dem  BASE TABLE   \n",
      "13     fairicube         cube                   cu_city_drought  BASE TABLE   \n",
      "14     fairicube         cube                 cu_city_env_zones  BASE TABLE   \n",
      "15     fairicube         cube       cu_city_era5_2m_temperature  BASE TABLE   \n",
      "16     fairicube         cube                  cu_city_eurostat  BASE TABLE   \n",
      "17     fairicube         cube   cu_city_hrl_imperviousness_2018  BASE TABLE   \n",
      "18     fairicube         cube        cu_city_hrl_treecover_2018  BASE TABLE   \n",
      "19     fairicube         cube               cu_city_urban_atlas  BASE TABLE   \n",
      "20     fairicube         cube       cu_city_water_classes_clc18  BASE TABLE   \n",
      "21     fairicube         cube                 cu_utci_indicator  BASE TABLE   \n",
      "22     fairicube         cube                 geography_columns  BASE TABLE   \n",
      "23     fairicube         cube                   spatial_ref_sys  BASE TABLE   \n",
      "24     fairicube         cube  v_city_burnt_area_wild_fire_long        VIEW   \n",
      "\n",
      "   self_referencing_column_name reference_generation  \\\n",
      "0                          None                 None   \n",
      "1                          None                 None   \n",
      "2                          None                 None   \n",
      "3                          None                 None   \n",
      "4                          None                 None   \n",
      "5                          None                 None   \n",
      "6                          None                 None   \n",
      "7                          None                 None   \n",
      "8                          None                 None   \n",
      "9                          None                 None   \n",
      "10                         None                 None   \n",
      "11                         None                 None   \n",
      "12                         None                 None   \n",
      "13                         None                 None   \n",
      "14                         None                 None   \n",
      "15                         None                 None   \n",
      "16                         None                 None   \n",
      "17                         None                 None   \n",
      "18                         None                 None   \n",
      "19                         None                 None   \n",
      "20                         None                 None   \n",
      "21                         None                 None   \n",
      "22                         None                 None   \n",
      "23                         None                 None   \n",
      "24                         None                 None   \n",
      "\n",
      "   user_defined_type_catalog user_defined_type_schema user_defined_type_name  \\\n",
      "0                       None                     None                   None   \n",
      "1                       None                     None                   None   \n",
      "2                       None                     None                   None   \n",
      "3                       None                     None                   None   \n",
      "4                       None                     None                   None   \n",
      "5                       None                     None                   None   \n",
      "6                       None                     None                   None   \n",
      "7                       None                     None                   None   \n",
      "8                       None                     None                   None   \n",
      "9                       None                     None                   None   \n",
      "10                      None                     None                   None   \n",
      "11                      None                     None                   None   \n",
      "12                      None                     None                   None   \n",
      "13                      None                     None                   None   \n",
      "14                      None                     None                   None   \n",
      "15                      None                     None                   None   \n",
      "16                      None                     None                   None   \n",
      "17                      None                     None                   None   \n",
      "18                      None                     None                   None   \n",
      "19                      None                     None                   None   \n",
      "20                      None                     None                   None   \n",
      "21                      None                     None                   None   \n",
      "22                      None                     None                   None   \n",
      "23                      None                     None                   None   \n",
      "24                      None                     None                   None   \n",
      "\n",
      "   is_insertable_into is_typed commit_action  \n",
      "0                 YES       NO          None  \n",
      "1                 YES       NO          None  \n",
      "2                 YES       NO          None  \n",
      "3                 YES       NO          None  \n",
      "4                 YES       NO          None  \n",
      "5                 YES       NO          None  \n",
      "6                 YES       NO          None  \n",
      "7                 YES       NO          None  \n",
      "8                 YES       NO          None  \n",
      "9                 YES       NO          None  \n",
      "10                YES       NO          None  \n",
      "11                YES       NO          None  \n",
      "12                YES       NO          None  \n",
      "13                YES       NO          None  \n",
      "14                YES       NO          None  \n",
      "15                YES       NO          None  \n",
      "16                YES       NO          None  \n",
      "17                YES       NO          None  \n",
      "18                YES       NO          None  \n",
      "19                YES       NO          None  \n",
      "20                YES       NO          None  \n",
      "21                YES       NO          None  \n",
      "22                YES       NO          None  \n",
      "23                YES       NO          None  \n",
      "24                 NO       NO          None  \n"
     ]
    }
   ],
   "source": [
    "print (\"get database overview\")\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query = text(\"\"\"\n",
    "SELECT * FROM information_schema.tables \n",
    "WHERE table_schema = 'cube' order by table_name\n",
    "    \"\"\")\n",
    "    df_overview = pd.read_sql_query(query, conn)\n",
    "print (df_overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.1) Adding missing metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Add new columns:\n",
      "B) update new columns:\n",
      "\n",
      "         \n",
      "UPDATE cube.c_city_eurostat_input \n",
      "SET\n",
      "        city_code =urau_code,\n",
      "        city_code_version ='ua_2021',\n",
      "        estat_code =indic_code,\n",
      "        ---parameter_value = -999,\n",
      "        \n",
      "        parameter = CONCAT('Urban Audit indicators -',indic_code),\n",
      "        lineage   = 'Data on European cities were collected in the Urban Audit and in the Large City Audit project - for more information open the datasource',\n",
      "        datasource ='https://ec.europa.eu/eurostat/cache/metadata/en/urb_esms.htm';  \n",
      "            \n",
      "         \n",
      "update of table done!\n"
     ]
    }
   ],
   "source": [
    "## (2.1) Adding missing metadata.\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"c_city_eurostat_input\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "query_new_columns = (\"\"\"\n",
    "ALTER TABLE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "ADD COLUMN city_code VARCHAR,\n",
    "ADD COLUMN city_code_version VARCHAR,\n",
    "ADD COLUMN parameter VARCHAR,\n",
    "ADD COLUMN lineage TEXT,\n",
    "ADD COLUMN datasource VARCHAR;\n",
    "         \"\"\")\n",
    "\n",
    "print (query_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "################ update columns:\n",
    "print (\"B) update new columns:\")\n",
    "query_update_new_columns = (\"\"\"\n",
    "         \n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "SET\n",
    "        city_code =urau_code,\n",
    "        city_code_version ='ua_2021',\n",
    "        estat_code =indic_code,\n",
    "        parameter = CONCAT('Urban Audit indicators -',indic_code),\n",
    "        lineage   = 'Data on European cities were collected in the Urban Audit and in the Large City Audit project - for more information open the datasource',\n",
    "        datasource ='https://ec.europa.eu/eurostat/cache/metadata/en/urb_esms.htm';\n",
    "         \"\"\")\n",
    "print (query_update_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_update_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "print (\"update of table done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.2) Solving NULL -> 0 problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Add new columns:\n",
      "\n",
      "         \n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2000 = 0 where drought_pressure_occurrence_gs_1km_2000 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2001 = 0 where drought_pressure_occurrence_gs_1km_2001 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2002 = 0 where drought_pressure_occurrence_gs_1km_2002 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2003 = 0 where drought_pressure_occurrence_gs_1km_2003 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2004 = 0 where drought_pressure_occurrence_gs_1km_2004 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2005 = 0 where drought_pressure_occurrence_gs_1km_2005 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2006 = 0 where drought_pressure_occurrence_gs_1km_2006 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2007 = 0 where drought_pressure_occurrence_gs_1km_2007 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2008 = 0 where drought_pressure_occurrence_gs_1km_2008 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2009 = 0 where drought_pressure_occurrence_gs_1km_2009 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2010 = 0 where drought_pressure_occurrence_gs_1km_2010 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2011 = 0 where drought_pressure_occurrence_gs_1km_2011 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2012 = 0 where drought_pressure_occurrence_gs_1km_2012 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2013 = 0 where drought_pressure_occurrence_gs_1km_2013 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2014 = 0 where drought_pressure_occurrence_gs_1km_2014 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2015 = 0 where drought_pressure_occurrence_gs_1km_2015 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2016 = 0 where drought_pressure_occurrence_gs_1km_2016 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2017 = 0 where drought_pressure_occurrence_gs_1km_2017 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2018 = 0 where drought_pressure_occurrence_gs_1km_2018 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2019 = 0 where drought_pressure_occurrence_gs_1km_2019 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2020 = 0 where drought_pressure_occurrence_gs_1km_2020 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2021 = 0 where drought_pressure_occurrence_gs_1km_2021 is NULL ;\n",
      "UPDATE cube.c_city_drought SET drought_pressure_occurrence_gs_1km_2022 = 0 where drought_pressure_occurrence_gs_1km_2022 is NULL ;\n",
      "         \n",
      "           \n",
      "         \n"
     ]
    }
   ],
   "source": [
    "schema = \"cube\"\n",
    "name_of_table = \"c_city_drought\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "update_query = (\"\"\"\n",
    "         \n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2000 = 0 where drought_pressure_occurrence_gs_1km_2000 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2001 = 0 where drought_pressure_occurrence_gs_1km_2001 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2002 = 0 where drought_pressure_occurrence_gs_1km_2002 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2003 = 0 where drought_pressure_occurrence_gs_1km_2003 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2004 = 0 where drought_pressure_occurrence_gs_1km_2004 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2005 = 0 where drought_pressure_occurrence_gs_1km_2005 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2006 = 0 where drought_pressure_occurrence_gs_1km_2006 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2007 = 0 where drought_pressure_occurrence_gs_1km_2007 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2008 = 0 where drought_pressure_occurrence_gs_1km_2008 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2009 = 0 where drought_pressure_occurrence_gs_1km_2009 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2010 = 0 where drought_pressure_occurrence_gs_1km_2010 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2011 = 0 where drought_pressure_occurrence_gs_1km_2011 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2012 = 0 where drought_pressure_occurrence_gs_1km_2012 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2013 = 0 where drought_pressure_occurrence_gs_1km_2013 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2014 = 0 where drought_pressure_occurrence_gs_1km_2014 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2015 = 0 where drought_pressure_occurrence_gs_1km_2015 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2016 = 0 where drought_pressure_occurrence_gs_1km_2016 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2017 = 0 where drought_pressure_occurrence_gs_1km_2017 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2018 = 0 where drought_pressure_occurrence_gs_1km_2018 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2019 = 0 where drought_pressure_occurrence_gs_1km_2019 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2020 = 0 where drought_pressure_occurrence_gs_1km_2020 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2021 = 0 where drought_pressure_occurrence_gs_1km_2021 is NULL ;\n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" SET drought_pressure_occurrence_gs_1km_2022 = 0 where drought_pressure_occurrence_gs_1km_2022 is NULL ;\n",
    "         \"\"\")\n",
    "\n",
    "print (update_query)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(update_query)\n",
    "connection.commit()\n",
    "\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.1) Transform tables (pivot, columns to rows ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation ob table:\n",
      "        estat_code urau_code city_code city_code_version  \\\n",
      "0               AT   DE1028I        AT           ua_2021   \n",
      "1               AT   DE1055i        AT           ua_2021   \n",
      "2           AT001C   DE1028I    AT001C           ua_2021   \n",
      "3           AT001C   DE1055i    AT001C           ua_2021   \n",
      "4           AT002C   DE1028I    AT002C           ua_2021   \n",
      "...            ...       ...       ...               ...   \n",
      "1534433     UK133C   DE1055i    UK133C           ua_2021   \n",
      "1534434     UK134C   DE1028I    UK134C           ua_2021   \n",
      "1534435     UK134C   DE1055i    UK134C           ua_2021   \n",
      "1534436     UK135C   DE1028I    UK135C           ua_2021   \n",
      "1534437     UK135C   DE1055i    UK135C           ua_2021   \n",
      "\n",
      "                                           parameter  \\\n",
      "0        \"Urban Audit indicators - check estat code\"   \n",
      "1        \"Urban Audit indicators - check estat code\"   \n",
      "2        \"Urban Audit indicators - check estat code\"   \n",
      "3        \"Urban Audit indicators - check estat code\"   \n",
      "4        \"Urban Audit indicators - check estat code\"   \n",
      "...                                              ...   \n",
      "1534433  \"Urban Audit indicators - check estat code\"   \n",
      "1534434  \"Urban Audit indicators - check estat code\"   \n",
      "1534435  \"Urban Audit indicators - check estat code\"   \n",
      "1534436  \"Urban Audit indicators - check estat code\"   \n",
      "1534437  \"Urban Audit indicators - check estat code\"   \n",
      "\n",
      "                                                   lineage  \\\n",
      "0        \"Data on European cities were collected in the...   \n",
      "1        \"Data on European cities were collected in the...   \n",
      "2        \"Data on European cities were collected in the...   \n",
      "3        \"Data on European cities were collected in the...   \n",
      "4        \"Data on European cities were collected in the...   \n",
      "...                                                    ...   \n",
      "1534433  \"Data on European cities were collected in the...   \n",
      "1534434  \"Data on European cities were collected in the...   \n",
      "1534435  \"Data on European cities were collected in the...   \n",
      "1534436  \"Data on European cities were collected in the...   \n",
      "1534437  \"Data on European cities were collected in the...   \n",
      "\n",
      "                                                datasource  year  \\\n",
      "0        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "1        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "2        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "3        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "4        \"https://ec.europa.eu/eurostat/cache/metadata/...  1991   \n",
      "...                                                    ...   ...   \n",
      "1534433  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "1534434  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "1534435  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "1534436  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "1534437  \"https://ec.europa.eu/eurostat/cache/metadata/...  2021   \n",
      "\n",
      "         parameter_value  \n",
      "0               8.094399  \n",
      "1               6.816773  \n",
      "2               9.061868  \n",
      "3               8.785802  \n",
      "4               9.533661  \n",
      "...                  ...  \n",
      "1534433              NaN  \n",
      "1534434              NaN  \n",
      "1534435              NaN  \n",
      "1534436              NaN  \n",
      "1534437              NaN  \n",
      "\n",
      "[1534438 rows x 9 columns]\n",
      "dataframe to sql:\n",
      "end transformation\n"
     ]
    }
   ],
   "source": [
    "## (A) bring  columns to rows::\n",
    "## bring sql table to data frame:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_city_eurostat_new\"\n",
    "\n",
    "## open connection:\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "connection.commit()\n",
    "## testing reading tables from database:\n",
    "\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query_wide_table = text(\"\"\"\n",
    "    SELECT estat_code, urau_code, \"1991\", \"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", city_code, city_code_version, parameter, lineage, datasource\n",
    "\tFROM cube.c_city_eurostat;\n",
    "    \"\"\")\n",
    "    df_wide_table = pd.read_sql_query(query_wide_table, conn)\n",
    "\n",
    "print (\"Transformation ob table:\")\n",
    "df_transformed_table =df_wide_table.melt(id_vars=[\n",
    "                    'estat_code', \n",
    "                    'urau_code', \n",
    "                    'city_code', \n",
    "                    'city_code_version', \n",
    "                    'parameter', \n",
    "                    'lineage', \n",
    "                    'datasource'\n",
    "                        ], var_name=\"year\", value_name=\"parameter_value\")\n",
    "print(df_transformed_table)\n",
    "print (\"dataframe to sql:\")\n",
    "\n",
    "###################################################\n",
    "#name_of_table = name_of_table\n",
    "export_df_to_sql = df_transformed_table  # dataframe to be exported\n",
    "schmema_name = schema\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "print (\"end transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation ob table:\n",
      "        estat_code urau_code city_code city_code_version  \\\n",
      "0          EN1002V    AT001C    AT001C           ua_2021   \n",
      "1          EN1002V    AT002C    AT002C           ua_2021   \n",
      "2          EN1002V    AT003C    AT003C           ua_2021   \n",
      "3          EN1002V    AT004C    AT004C           ua_2021   \n",
      "4          EN1002V    AT005C    AT005C           ua_2021   \n",
      "...            ...       ...       ...               ...   \n",
      "1478323    TT1080V    UK024C    UK024C           ua_2021   \n",
      "1478324    TT1080V    UK027C    UK027C           ua_2021   \n",
      "1478325    TT1080V    UK029C    UK029C           ua_2021   \n",
      "1478326    TT1080V    UK030C    UK030C           ua_2021   \n",
      "1478327    TT1080V    UK062C    UK062C           ua_2021   \n",
      "\n",
      "                               parameter  \\\n",
      "0        Urban Audit indicators -EN1002V   \n",
      "1        Urban Audit indicators -EN1002V   \n",
      "2        Urban Audit indicators -EN1002V   \n",
      "3        Urban Audit indicators -EN1002V   \n",
      "4        Urban Audit indicators -EN1002V   \n",
      "...                                  ...   \n",
      "1478323  Urban Audit indicators -TT1080V   \n",
      "1478324  Urban Audit indicators -TT1080V   \n",
      "1478325  Urban Audit indicators -TT1080V   \n",
      "1478326  Urban Audit indicators -TT1080V   \n",
      "1478327  Urban Audit indicators -TT1080V   \n",
      "\n",
      "                                                   lineage  \\\n",
      "0        Data on European cities were collected in the ...   \n",
      "1        Data on European cities were collected in the ...   \n",
      "2        Data on European cities were collected in the ...   \n",
      "3        Data on European cities were collected in the ...   \n",
      "4        Data on European cities were collected in the ...   \n",
      "...                                                    ...   \n",
      "1478323  Data on European cities were collected in the ...   \n",
      "1478324  Data on European cities were collected in the ...   \n",
      "1478325  Data on European cities were collected in the ...   \n",
      "1478326  Data on European cities were collected in the ...   \n",
      "1478327  Data on European cities were collected in the ...   \n",
      "\n",
      "                                                datasource  year  \\\n",
      "0        https://ec.europa.eu/eurostat/cache/metadata/e...  1991   \n",
      "1        https://ec.europa.eu/eurostat/cache/metadata/e...  1991   \n",
      "2        https://ec.europa.eu/eurostat/cache/metadata/e...  1991   \n",
      "3        https://ec.europa.eu/eurostat/cache/metadata/e...  1991   \n",
      "4        https://ec.europa.eu/eurostat/cache/metadata/e...  1991   \n",
      "...                                                    ...   ...   \n",
      "1478323  https://ec.europa.eu/eurostat/cache/metadata/e...  2021   \n",
      "1478324  https://ec.europa.eu/eurostat/cache/metadata/e...  2021   \n",
      "1478325  https://ec.europa.eu/eurostat/cache/metadata/e...  2021   \n",
      "1478326  https://ec.europa.eu/eurostat/cache/metadata/e...  2021   \n",
      "1478327  https://ec.europa.eu/eurostat/cache/metadata/e...  2021   \n",
      "\n",
      "         parameter_value  \n",
      "0                    NaN  \n",
      "1                    NaN  \n",
      "2                    NaN  \n",
      "3                    NaN  \n",
      "4                    NaN  \n",
      "...                  ...  \n",
      "1478323              NaN  \n",
      "1478324              NaN  \n",
      "1478325              NaN  \n",
      "1478326              NaN  \n",
      "1478327              NaN  \n",
      "\n",
      "[1478328 rows x 9 columns]\n",
      "dataframe to sql:\n",
      "end transformation\n"
     ]
    }
   ],
   "source": [
    "## (A) bring  volumns to rows::\n",
    "## bring sql table to data frame:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_city_eurostat_long\" \n",
    "\n",
    "## open connection:\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "connection.commit()\n",
    "## testing reading tables from database:\n",
    "\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query_wide_table = text(\"\"\"\n",
    "     SELECT  urau_code, \"1991\", \"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \n",
    "        \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \n",
    "        \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \n",
    "        \"2019\", \"2020\", \"2021\", city_code, city_code_version, parameter, estat_code, lineage, datasource\n",
    "    FROM cube.c_city_eurostat\n",
    "    \"\"\")\n",
    "    df_wide_table = pd.read_sql_query(query_wide_table, conn)\n",
    "print (\"Transformation ob table:\")\n",
    "df_transformed_table =df_wide_table.melt(id_vars=[\n",
    "                    'estat_code', \n",
    "                    'urau_code', \n",
    "                    'city_code', \n",
    "                    'city_code_version', \n",
    "                    'parameter', \n",
    "                    'lineage', \n",
    "                    'datasource'\n",
    "                        ], var_name=\"year\", value_name=\"parameter_value\")\n",
    "print(df_transformed_table)\n",
    "print (\"dataframe to sql:\")\n",
    "\n",
    "###################################################\n",
    "#name_of_table = name_of_table\n",
    "export_df_to_sql = df_transformed_table  # dataframe to be exported\n",
    "schmema_name = schema\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "print (\"end transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation ob table:\n",
      "end transformation\n"
     ]
    }
   ],
   "source": [
    "## (B)bring row to columns:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"c_city_eurostat_wide\" #ouput\n",
    "\n",
    "\n",
    "## open connection:\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "connection.commit()\n",
    "## testing reading tables from database:\n",
    "\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query_long_table = text(\"\"\"\n",
    "    \n",
    "SELECT  \n",
    "      \n",
    "            estat_code, \n",
    "            city_code, \n",
    "            city_code_version, \n",
    "            parameter, \n",
    "            lineage, \n",
    "            datasource, \n",
    "            year, \n",
    "            parameter_value\n",
    "\n",
    "            FROM cube.cu_city_eurostat\n",
    "     ;\n",
    "    \n",
    "    \"\"\")\n",
    "    df_wide_table = pd.read_sql_query(query_long_table, conn)\n",
    "    \n",
    "    \n",
    "#print (df_wide_table)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Transformation ob table:\")\n",
    "\n",
    "\n",
    "res = df_wide_table.pivot_table(index=['city_code', \n",
    "            'estat_code', \n",
    "            'city_code_version', \n",
    "            'parameter', \n",
    "            'lineage', \n",
    "            'datasource'          \n",
    "        ]    \n",
    ", columns='year',\n",
    "                     values='parameter_value', aggfunc='first').reset_index()\n",
    "\n",
    "\n",
    "###################################################\n",
    "name_of_table = name_of_table\n",
    "export_df_to_sql = res  # dataframe to be exported#\n",
    "schmema_name = schema\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "print (\"end transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B) update new columns:\n",
      "\n",
      "         \n",
      "UPDATE cube.c_city_eurostat_wide \n",
      "SET\n",
      " parameter = CONCAT('Urban Audit indicators -',estat_code),\n",
      " lineage   = 'Data on European cities were collected in the Urban Audit and in the Large City Audit project - for more information open the datasource',\n",
      " datasource ='https://ec.europa.eu/eurostat/cache/metadata/en/urb_esms.htm';\n",
      "             \n",
      "         \n"
     ]
    }
   ],
   "source": [
    "\n",
    "## update last transformation results\n",
    "schema = \"cube\"\n",
    "name_of_table = \"c_city_eurostat_wide\" #ouput\n",
    "################ update columns:\n",
    "print (\"B) update new columns:\")\n",
    "query_update_new_columns = (\"\"\"\n",
    "         \n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "SET\n",
    " parameter = CONCAT('Urban Audit indicators -',estat_code),\n",
    " lineage   = 'Data on European cities were collected in the Urban Audit and in the Large City Audit project - for more information open the datasource',\n",
    " datasource ='https://ec.europa.eu/eurostat/cache/metadata/en/urb_esms.htm';\n",
    "             \n",
    "         \"\"\")\n",
    "print (query_update_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_update_new_columns)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation ob table:\n",
      "end transformation\n"
     ]
    }
   ],
   "source": [
    "## (B)bring row to columns:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"c_city_water_classes_clc18\" #ouput\n",
    "\n",
    "\n",
    "## open connection:\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "connection.commit()\n",
    "## testing reading tables from database:\n",
    "\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query_long_table = text(\"\"\"\n",
    "    \n",
    "SELECT \n",
    "        clc_code, \n",
    "        ---pixel_count,\n",
    "        pixel_count_norm, \n",
    "        city_code, \n",
    "        city_code_version, \n",
    "        parameter, \n",
    "        parameter_id, \n",
    "        parameter_value, \n",
    "        lineage, \n",
    "        datasource\n",
    "\n",
    "FROM cube.cu_city_water_classes_clc18\n",
    "                            \n",
    "                            ;\n",
    "    \n",
    "    \"\"\")\n",
    "    df_wide_table = pd.read_sql_query(query_long_table, conn)\n",
    "    \n",
    "    \n",
    "#print (df_wide_table)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Transformation ob table:\")\n",
    "\n",
    "\n",
    "res = df_wide_table.pivot_table(index=['city_code', \n",
    "        'city_code_version', \n",
    "        'parameter', \n",
    "        'parameter_id', \n",
    "        'lineage', \n",
    "        'datasource']    \n",
    ", columns='clc_code',\n",
    "                     values='pixel_count_norm', aggfunc='first').reset_index()\n",
    "\n",
    "## rename columns:\n",
    "df_final = res.rename(columns={\n",
    "                        40 : 'clc_water_courses_40',\n",
    "                        41 : 'clc_water_bodies_41',\n",
    "                        42 : 'clc_coastal_lagoons_42',\n",
    "                        43 : 'clc_estuaries_43',\n",
    "                        44 : 'clc_sea_and_ocean_44'})\n",
    "\n",
    "\n",
    "## print (\"dataframe to sql:\")\n",
    "\n",
    "###################################################\n",
    "name_of_table = name_of_table\n",
    "export_df_to_sql = df_final  # dataframe to be exported#\n",
    "schmema_name = schema\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "print (\"end transformation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation ob table:\n",
      "end transformation\n"
     ]
    }
   ],
   "source": [
    "## (B)bring row to columns:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"c_utci_indicator_test\" #ouput\n",
    "\n",
    "## open connection:\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "connection.commit()\n",
    "## testing reading tables from database:\n",
    "\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query_long_table = text(\"\"\"\n",
    "    \n",
    "SELECT \n",
    "        utci_class, year, city_code, city_code_version, parameter, parameter_value, lineage, datasource\n",
    "\n",
    "FROM cube.cu_utci_indicator\n",
    "                            \n",
    "                            ;\n",
    "    \n",
    "    \"\"\")\n",
    "    df_wide_table = pd.read_sql_query(query_long_table, conn)\n",
    "    \n",
    "    \n",
    "#print (df_wide_table)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Transformation ob table:\")\n",
    "\n",
    "\n",
    "\n",
    "#utci_class, \n",
    "#year,\n",
    "#parameter_value, \n",
    "\n",
    "\n",
    "res = df_wide_table.pivot_table(index=[\n",
    "             'utci_class'\n",
    "            ,'city_code'\n",
    "            ,'city_code_version'\n",
    "            ,'parameter'\n",
    "            ,'lineage'\n",
    "            ,'datasource']    \n",
    ", columns='year',\n",
    "                     values='parameter_value', aggfunc='first').reset_index()\n",
    "\n",
    "## rename columns:\n",
    "#df_final = res.rename(columns={\n",
    "#                        40 : 'clc_water_courses_40',\n",
    "#                        41 : 'clc_water_bodies_41',\n",
    "#                        42 : 'clc_coastal_lagoons_42',\n",
    "#                        43 : 'clc_estuaries_43',\n",
    "#                        44 : 'clc_sea_and_ocean_44'})\n",
    "\n",
    "\n",
    "## print (\"dataframe to sql:\")\n",
    "\n",
    "###################################################\n",
    "name_of_table = name_of_table\n",
    "export_df_to_sql = res  # dataframe to be exported#\n",
    "schmema_name = schema\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "print (\"end transformation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>city_code</th>\n",
       "      <th>city_code_version</th>\n",
       "      <th>parameter</th>\n",
       "      <th>lineage</th>\n",
       "      <th>datasource</th>\n",
       "      <th colspan=\"5\" halign=\"left\">2018</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">2022</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utci_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Extreme Cold Stress</th>\n",
       "      <th>Extreme Heat Stress</th>\n",
       "      <th>Moderate Cold Stress</th>\n",
       "      <th>Moderate Heat Stress</th>\n",
       "      <th>No Thermal Stress</th>\n",
       "      <th>...</th>\n",
       "      <th>Extreme Cold Stress</th>\n",
       "      <th>Extreme Heat Stress</th>\n",
       "      <th>Moderate Cold Stress</th>\n",
       "      <th>Moderate Heat Stress</th>\n",
       "      <th>No Thermal Stress</th>\n",
       "      <th>Slight Cold Stress</th>\n",
       "      <th>Strong Cold Stress</th>\n",
       "      <th>Strong Heat Stress</th>\n",
       "      <th>Very Strong Cold Stress</th>\n",
       "      <th>Very Strong Heat Stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT001C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT001C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT001C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT001C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT001C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>UK586C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6310</th>\n",
       "      <td>UK586C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311</th>\n",
       "      <td>UK586C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6312</th>\n",
       "      <td>UK586C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6313</th>\n",
       "      <td>UK586C1</td>\n",
       "      <td>ua_2021</td>\n",
       "      <td>Number days per year of UTCI-class (derived fr...</td>\n",
       "      <td>The night hours were first extracted from the ...</td>\n",
       "      <td>cds.climate.copernicus.eu -&gt; https://cds.clima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6314 rows Ã 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "year       city_code city_code_version  \\\n",
       "utci_class                               \n",
       "0            AT001C1           ua_2021   \n",
       "1            AT001C1           ua_2021   \n",
       "2            AT001C1           ua_2021   \n",
       "3            AT001C1           ua_2021   \n",
       "4            AT001C1           ua_2021   \n",
       "...              ...               ...   \n",
       "6309         UK586C1           ua_2021   \n",
       "6310         UK586C1           ua_2021   \n",
       "6311         UK586C1           ua_2021   \n",
       "6312         UK586C1           ua_2021   \n",
       "6313         UK586C1           ua_2021   \n",
       "\n",
       "year                                                parameter  \\\n",
       "utci_class                                                      \n",
       "0           Number days per year of UTCI-class (derived fr...   \n",
       "1           Number days per year of UTCI-class (derived fr...   \n",
       "2           Number days per year of UTCI-class (derived fr...   \n",
       "3           Number days per year of UTCI-class (derived fr...   \n",
       "4           Number days per year of UTCI-class (derived fr...   \n",
       "...                                                       ...   \n",
       "6309        Number days per year of UTCI-class (derived fr...   \n",
       "6310        Number days per year of UTCI-class (derived fr...   \n",
       "6311        Number days per year of UTCI-class (derived fr...   \n",
       "6312        Number days per year of UTCI-class (derived fr...   \n",
       "6313        Number days per year of UTCI-class (derived fr...   \n",
       "\n",
       "year                                                  lineage  \\\n",
       "utci_class                                                      \n",
       "0           The night hours were first extracted from the ...   \n",
       "1           The night hours were first extracted from the ...   \n",
       "2           The night hours were first extracted from the ...   \n",
       "3           The night hours were first extracted from the ...   \n",
       "4           The night hours were first extracted from the ...   \n",
       "...                                                       ...   \n",
       "6309        The night hours were first extracted from the ...   \n",
       "6310        The night hours were first extracted from the ...   \n",
       "6311        The night hours were first extracted from the ...   \n",
       "6312        The night hours were first extracted from the ...   \n",
       "6313        The night hours were first extracted from the ...   \n",
       "\n",
       "year                                               datasource  \\\n",
       "utci_class                                                      \n",
       "0           cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "1           cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "2           cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "3           cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "4           cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "...                                                       ...   \n",
       "6309        cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "6310        cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "6311        cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "6312        cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "6313        cds.climate.copernicus.eu -> https://cds.clima...   \n",
       "\n",
       "year                      2018                                           \\\n",
       "utci_class Extreme Cold Stress Extreme Heat Stress Moderate Cold Stress   \n",
       "0                          NaN                 NaN                129.0   \n",
       "1                          NaN                 NaN                  NaN   \n",
       "2                          NaN                 NaN                  NaN   \n",
       "3                          NaN                 NaN                  NaN   \n",
       "4                          NaN                 NaN                  NaN   \n",
       "...                        ...                 ...                  ...   \n",
       "6309                       NaN                 NaN                  NaN   \n",
       "6310                       NaN                 NaN                  NaN   \n",
       "6311                       NaN                 NaN                  NaN   \n",
       "6312                       NaN                 NaN                  NaN   \n",
       "6313                       NaN                 NaN                  NaN   \n",
       "\n",
       "year                                               ...                2022  \\\n",
       "utci_class Moderate Heat Stress No Thermal Stress  ... Extreme Cold Stress   \n",
       "0                           NaN               NaN  ...                 NaN   \n",
       "1                         114.0               NaN  ...                 NaN   \n",
       "2                           NaN             283.0  ...                 NaN   \n",
       "3                           NaN               NaN  ...                 NaN   \n",
       "4                           NaN               NaN  ...                 NaN   \n",
       "...                         ...               ...  ...                 ...   \n",
       "6309                       24.0               NaN  ...                 NaN   \n",
       "6310                        NaN             289.0  ...                 NaN   \n",
       "6311                        NaN               NaN  ...                 NaN   \n",
       "6312                        NaN               NaN  ...                 NaN   \n",
       "6313                        NaN               NaN  ...                 NaN   \n",
       "\n",
       "year                                                                      \\\n",
       "utci_class Extreme Heat Stress Moderate Cold Stress Moderate Heat Stress   \n",
       "0                          NaN                138.0                  NaN   \n",
       "1                          NaN                  NaN                 86.0   \n",
       "2                          NaN                  NaN                  NaN   \n",
       "3                          NaN                  NaN                  NaN   \n",
       "4                          NaN                  NaN                  NaN   \n",
       "...                        ...                  ...                  ...   \n",
       "6309                       NaN                  NaN                 12.0   \n",
       "6310                       NaN                  NaN                  NaN   \n",
       "6311                       NaN                  NaN                  NaN   \n",
       "6312                       NaN                  NaN                  NaN   \n",
       "6313                       NaN                  NaN                  NaN   \n",
       "\n",
       "year                                                                \\\n",
       "utci_class No Thermal Stress Slight Cold Stress Strong Cold Stress   \n",
       "0                        NaN                NaN                NaN   \n",
       "1                        NaN                NaN                NaN   \n",
       "2                      314.0                NaN                NaN   \n",
       "3                        NaN              135.0                NaN   \n",
       "4                        NaN                NaN               15.0   \n",
       "...                      ...                ...                ...   \n",
       "6309                     NaN                NaN                NaN   \n",
       "6310                   346.0                NaN                NaN   \n",
       "6311                     NaN              219.0                NaN   \n",
       "6312                     NaN                NaN                7.0   \n",
       "6313                     NaN                NaN                NaN   \n",
       "\n",
       "year                                                                           \n",
       "utci_class Strong Heat Stress Very Strong Cold Stress Very Strong Heat Stress  \n",
       "0                         NaN                     NaN                     NaN  \n",
       "1                         NaN                     NaN                     NaN  \n",
       "2                         NaN                     NaN                     NaN  \n",
       "3                         NaN                     NaN                     NaN  \n",
       "4                         NaN                     NaN                     NaN  \n",
       "...                       ...                     ...                     ...  \n",
       "6309                      NaN                     NaN                     NaN  \n",
       "6310                      NaN                     NaN                     NaN  \n",
       "6311                      NaN                     NaN                     NaN  \n",
       "6312                      NaN                     NaN                     NaN  \n",
       "6313                      1.0                     NaN                     NaN  \n",
       "\n",
       "[6314 rows x 54 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send table to SQL:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m schmema_name \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcube\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m###################################################\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mexport_df_to_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_of_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_postgresql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschmema_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2987\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2831\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2832\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2983\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   2984\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa:E501\u001b[39;00m\n\u001b[0;32m   2985\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 2987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2988\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2998\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:695\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    692\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    693\u001b[0m     )\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m    696\u001b[0m     frame,\n\u001b[0;32m    697\u001b[0m     name,\n\u001b[0;32m    698\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m    699\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    700\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m    701\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    702\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    703\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    704\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    705\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    707\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:1738\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1726\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m   1728\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[0;32m   1729\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   1730\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1736\u001b[0m )\n\u001b[1;32m-> 1738\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[0;32m   1739\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m   1740\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectable,\n\u001b[0;32m   1741\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   1742\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   1743\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   1744\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   1745\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   1746\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m   1748\u001b[0m )\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:1325\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mSQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(1054, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf(e0)?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield list\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m))(?#\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;124m    )|inf can not be used with MySQL\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:946\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    945\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[1;32m--> 946\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(num_inserted):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:853\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    852\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[1;32m--> 853\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1306\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1302\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[0;32m   1303\u001b[0m         exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[38;5;241m=\u001b[39merr\n\u001b[0;32m   1304\u001b[0m     )\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\elements.py:332\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    330\u001b[0m ):\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[1;32m--> 332\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1498\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[0;32m   1486\u001b[0m compiled_cache \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1488\u001b[0m )\n\u001b[0;32m   1490\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1491\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1492\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1497\u001b[0m )\n\u001b[1;32m-> 1498\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1512\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1513\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1517\u001b[0m         ret,\n\u001b[0;32m   1518\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2047\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2043\u001b[0m         util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[0;32m   2044\u001b[0m             sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[0;32m   2045\u001b[0m         )\n\u001b[0;32m   2046\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2047\u001b[0m         \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1799\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1797\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1798\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1799\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_executemany\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n\u001b[0;32m   1803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\psycopg2.py:953\u001b[0m, in \u001b[0;36mPGDialect_psycopg2.do_executemany\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    951\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    952\u001b[0m     xtras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_psycopg2_extras()\n\u001b[1;32m--> 953\u001b[0m     context\u001b[38;5;241m.\u001b[39m_psycopg2_fetched_rows \u001b[38;5;241m=\u001b[39m xtras\u001b[38;5;241m.\u001b[39mexecute_values(\n\u001b[0;32m    954\u001b[0m         cursor,\n\u001b[0;32m    955\u001b[0m         statement,\n\u001b[0;32m    956\u001b[0m         parameters,\n\u001b[0;32m    957\u001b[0m         template\u001b[38;5;241m=\u001b[39mexecutemany_values,\n\u001b[0;32m    958\u001b[0m         fetch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(context\u001b[38;5;241m.\u001b[39mcompiled\u001b[38;5;241m.\u001b[39mreturning),\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    960\u001b[0m     )\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_mode \u001b[38;5;241m&\u001b[39m EXECUTEMANY_BATCH:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutemany_batch_page_size:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\psycopg2\\extras.py:1299\u001b[0m, in \u001b[0;36mexecute_values\u001b[1;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1298\u001b[0m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m post\n\u001b[1;32m-> 1299\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch:\n\u001b[0;32m   1301\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(cur\u001b[38;5;241m.\u001b[39mfetchall())\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print (\"send table to SQL:\")\n",
    "\n",
    "###################################################\n",
    "name_of_table = 'cu_test'\n",
    "export_df_to_sql = df_transformed_table  # dataframe to be exported\n",
    "schmema_name ='cube'\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "\n",
    "\n",
    "\n",
    "## close connection:\n",
    "#cursor.close()\n",
    "#connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.1) VIEW 1 ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3.1) Set up of VIEW\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_urban_atlas_test\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "query_view = (\"\"\"\n",
    "         \n",
    "-- View: cube.CITY_main_cube\n",
    "\n",
    "-- DROP VIEW cube.\"CITY_main_cube\";\n",
    "\n",
    "CREATE OR REPLACE VIEW cube.\"CITY_main_cube\"\n",
    " AS\n",
    "\n",
    " SELECT cu_city_drought.city_code,\n",
    "    cu_city_drought.city_code_version,\n",
    "    cu_city_drought.parameter,\n",
    "    cu_city_drought.parameter_id,\n",
    "    cu_city_drought.parameter_value,\n",
    "    cu_city_drought.year\n",
    "   FROM cube.cu_city_drought\n",
    "UNION\n",
    " SELECT cu_city_burnt_area_wild_fire.city_code,\n",
    "    cu_city_burnt_area_wild_fire.city_code_version,\n",
    "    cu_city_burnt_area_wild_fire.parameter,\n",
    "    cu_city_burnt_area_wild_fire.parameter_id,\n",
    "    cu_city_burnt_area_wild_fire.parameter_value,\n",
    "    cu_city_burnt_area_wild_fire.year\n",
    "   FROM cube.cu_city_burnt_area_wild_fire\n",
    "UNION\n",
    " SELECT cu_urban_atlas.city_code,\n",
    "    cu_urban_atlas.city_code_version,\n",
    "    cu_urban_atlas.parameter,\n",
    "    cu_urban_atlas.parameter_id,\n",
    "    cu_urban_atlas.parameter_value,\n",
    "    cu_urban_atlas.year\n",
    "   FROM cube.cu_urban_atlas\n",
    "UNION\n",
    " SELECT cu_city_eurostat.city_code,\n",
    "    cu_city_eurostat.city_code_version,\n",
    "    cu_city_eurostat.parameter,\n",
    "    cu_city_eurostat.parameter_id,\n",
    "    cu_city_eurostat.parameter_value,\n",
    "    cu_city_eurostat.year\n",
    "   FROM cube.cu_city_eurostat\n",
    "UNION\n",
    " SELECT cu_city_treecover.city_code,\n",
    "    cu_city_treecover.city_code_version,\n",
    "    cu_city_treecover.parameter,\n",
    "    cu_city_treecover.parameter_id,\n",
    "    cu_city_treecover.parameter_value,\n",
    "    cu_city_treecover.year\n",
    "   FROM cube.cu_city_treecover\n",
    "UNION\n",
    " SELECT cu_city_dem.city_code,\n",
    "    cu_city_dem.city_code_version,\n",
    "    cu_city_dem.parameter,\n",
    "    cu_city_dem.parameter_id,\n",
    "    cu_city_dem.parameter_value,\n",
    "    cu_city_dem.year\n",
    "   FROM cube.xxcu_city_dem_mean\n",
    "UNION\n",
    " SELECT cu_city_imperviousness_area.city_code,\n",
    "    cu_city_imperviousness_area.city_code_version,\n",
    "    cu_city_imperviousness_area.parameter,\n",
    "    cu_city_imperviousness_area.parameter_id,\n",
    "    cu_city_imperviousness_area.parameter_value,\n",
    "    cu_city_imperviousness_area.year\n",
    "   FROM cube.cu_city_imperviousness_area;\n",
    "     \n",
    "            \n",
    "         \"\"\")\n",
    "\n",
    "print (query_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_view)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Add new columns:\n",
      "\n",
      "         \n",
      "ALTER TABLE cube.cu_city_era5_summer_days_ml \n",
      "--ADD COLUMN city_code VARCHAR,\n",
      "ADD COLUMN city_code_version VARCHAR\n",
      "--ADD COLUMN parameter VARCHAR,\n",
      "\n",
      "--ADD COLUMN parameter_value FLOAT,\n",
      "--ADD COLUMN lineage TEXT,\n",
      "--ADD COLUMN datasource VARCHAR;\n",
      "         \n",
      "           \n",
      "         \n"
     ]
    },
    {
     "ename": "DuplicateColumn",
     "evalue": "column \"city_code_version\" of relation \"cu_city_era5_summer_days_ml\" already exists\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateColumn\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m connection \u001b[38;5;241m=\u001b[39m engine_postgresql\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m     25\u001b[0m cursor \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_new_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m connection\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m################ update columns:\u001b[39;00m\n",
      "\u001b[1;31mDuplicateColumn\u001b[0m: column \"city_code_version\" of relation \"cu_city_era5_summer_days_ml\" already exists\n"
     ]
    }
   ],
   "source": [
    "### updates climatg\n",
    "\n",
    "## (2.1) Adding missing metadata.\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_city_era5_summer_days_ml\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "query_new_columns = (\"\"\"\n",
    "         \n",
    "ALTER TABLE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "--ADD COLUMN city_code VARCHAR,\n",
    "ADD COLUMN city_code_version VARCHAR\n",
    "--ADD COLUMN parameter VARCHAR,\n",
    "\n",
    "--ADD COLUMN parameter_value FLOAT,\n",
    "--ADD COLUMN lineage TEXT,\n",
    "--ADD COLUMN datasource VARCHAR;\n",
    "         \n",
    "           \n",
    "         \"\"\")\n",
    "\n",
    "print (query_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "################ update columns:\n",
    "print (\"B) update new columns:\")\n",
    "query_update_new_columns = (\"\"\"\n",
    "         \n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "SET\n",
    "        --city_code =urau_code,\n",
    "        city_code_version ='ua_2021'\n",
    "        --estat_code =indic_code,\n",
    "        ---parameter_value = -999,\n",
    "        \n",
    "       -- parameter = CONCAT('Urban Audit indicators -',indic_code),\n",
    "        --lineage   = 'Data on European cities were collected in the Urban Audit and in the Large City Audit project - for more information open the datasource',\n",
    "        --datasource ='https://ec.europa.eu/eurostat/cache/metadata/en/urb_esms.htm';  \n",
    "            \n",
    "         \"\"\")\n",
    "print (query_update_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_update_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "print (\"update of table done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation ob table:\n",
      "end transformation\n"
     ]
    }
   ],
   "source": [
    "## (B)bring row to columns:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_city_era5_summer_days_ml\" #ouput\n",
    "\n",
    "\n",
    "## open connection:\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "connection.commit()\n",
    "## testing reading tables from database:\n",
    "\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query_long_table = text(\"\"\"\n",
    "    \n",
    "SELECT city_code, parameter_value,city_code_version, year, parameter, parameter_id, lineage, datasource\n",
    "\tFROM cube.cu_city_era5_summer_days_ml ;\n",
    "     \n",
    "    \n",
    "    \"\"\")\n",
    "    df_wide_table = pd.read_sql_query(query_long_table, conn)\n",
    "    \n",
    "    \n",
    "#print (df_wide_table)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Transformation ob table:\")\n",
    "\n",
    "\n",
    "res = df_wide_table.pivot_table(index=['city_code', \n",
    "     \n",
    "            'city_code_version', \n",
    "            'parameter', \n",
    "            'parameter_id',\n",
    "            'lineage', \n",
    "            'datasource' ]    \n",
    ", columns='year',\n",
    "                     values='parameter_value', aggfunc='first').reset_index()\n",
    "\n",
    "\n",
    "###################################################\n",
    "name_of_table = name_of_table\n",
    "export_df_to_sql = res  # dataframe to be exported#\n",
    "schmema_name = schema\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "print (\"end transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year city_code city_code_version  \\\n",
      "0      AT001C1           ua_2021   \n",
      "1      AT002C1           ua_2021   \n",
      "2      AT003C1           ua_2021   \n",
      "3      AT004C1           ua_2021   \n",
      "4      AT005C1           ua_2021   \n",
      "..         ...               ...   \n",
      "915    UK582C1           ua_2021   \n",
      "916    UK583C1           ua_2021   \n",
      "917    UK584C1           ua_2021   \n",
      "918    UK585C1           ua_2021   \n",
      "919    UK586C1           ua_2021   \n",
      "\n",
      "year                                          parameter  \\\n",
      "0     Count of summer days (>25 degrees) per year pe...   \n",
      "1     Count of summer days (>25 degrees) per year pe...   \n",
      "2     Count of summer days (>25 degrees) per year pe...   \n",
      "3     Count of summer days (>25 degrees) per year pe...   \n",
      "4     Count of summer days (>25 degrees) per year pe...   \n",
      "..                                                  ...   \n",
      "915   Count of summer days (>25 degrees) per year pe...   \n",
      "916   Count of summer days (>25 degrees) per year pe...   \n",
      "917   Count of summer days (>25 degrees) per year pe...   \n",
      "918   Count of summer days (>25 degrees) per year pe...   \n",
      "919   Count of summer days (>25 degrees) per year pe...   \n",
      "\n",
      "year                 parameter_id  \\\n",
      "0     city_era5_summer_days_count   \n",
      "1     city_era5_summer_days_count   \n",
      "2     city_era5_summer_days_count   \n",
      "3     city_era5_summer_days_count   \n",
      "4     city_era5_summer_days_count   \n",
      "..                            ...   \n",
      "915   city_era5_summer_days_count   \n",
      "916   city_era5_summer_days_count   \n",
      "917   city_era5_summer_days_count   \n",
      "918   city_era5_summer_days_count   \n",
      "919   city_era5_summer_days_count   \n",
      "\n",
      "year                                            lineage  \\\n",
      "0     https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "1     https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "2     https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "3     https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "4     https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "..                                                  ...   \n",
      "915   https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "916   https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "917   https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "918   https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "919   https://github.com/FAIRiCUBE/uc1-urban-climate...   \n",
      "\n",
      "year                                         datasource  2018  2021  \n",
      "0     https://cloud.google.com/storage/docs/public-d...  92.0  65.0  \n",
      "1     https://cloud.google.com/storage/docs/public-d...  30.0  28.0  \n",
      "2     https://cloud.google.com/storage/docs/public-d...  45.0  31.0  \n",
      "3     https://cloud.google.com/storage/docs/public-d...  58.0  33.0  \n",
      "4     https://cloud.google.com/storage/docs/public-d...   8.0  10.0  \n",
      "..                                                  ...   ...   ...  \n",
      "915   https://cloud.google.com/storage/docs/public-d...  27.0  12.0  \n",
      "916   https://cloud.google.com/storage/docs/public-d...  30.0  11.0  \n",
      "917   https://cloud.google.com/storage/docs/public-d...   2.0   1.0  \n",
      "918   https://cloud.google.com/storage/docs/public-d...   2.0   1.0  \n",
      "919   https://cloud.google.com/storage/docs/public-d...   6.0   4.0  \n",
      "\n",
      "[920 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Add new columns:\n",
      "\n",
      "         \n",
      "ALTER TABLE cube.c_city_water_classes_clc18 \n",
      "ADD COLUMN city_code VARCHAR,\n",
      "ADD COLUMN city_code_version VARCHAR,\n",
      "ADD COLUMN parameter VARCHAR,\n",
      "ADD COLUMN parameter_id VARCHAR, \n",
      "ADD COLUMN parameter_value FLOAT,\n",
      "ADD COLUMN lineage TEXT,\n",
      "ADD COLUMN datasource VARCHAR;        \n",
      "         \n",
      "B) update new columns:\n",
      "\n",
      "         \n",
      "UPDATE cube.c_city_water_classes_clc18 \n",
      "SET\n",
      "city_code = urau_code,\n",
      "city_code_version ='ua_2021',\n",
      "parameter = '\"Urban Audit indicators - check estat code\"',\n",
      "parameter_value = pixel_count_norm ,\n",
      " parameter_id = 'city_clc2018_water_in_and_around',\n",
      " lineage   = 'Get land cover data from CLC 2018 in and around city, by creating a buffer around city geometry. This notebook focuses on Water classes (CLC4**): https://github.com/FAIRiCUBE/uc1-urban-climate/blob/master/notebooks/dev/f02_cube/subcubes_CLC2018_400.ipynb',\n",
      " datasource ='https://land.copernicus.eu/en/products/corine-land-cover';\n",
      "         \n",
      "            \n",
      "         \n",
      "update of table done!\n"
     ]
    }
   ],
   "source": [
    "## (2.1) Adding missing metadata.\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table =  \"c_city_water_classes_clc18\"\n",
    "\n",
    "print (\"A) Add new columns:\")\n",
    "query_new_columns = (\"\"\"\n",
    "         \n",
    "ALTER TABLE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "ADD COLUMN city_code VARCHAR,\n",
    "ADD COLUMN city_code_version VARCHAR,\n",
    "ADD COLUMN parameter VARCHAR,\n",
    "ADD COLUMN parameter_id VARCHAR, \n",
    "ADD COLUMN parameter_value FLOAT,\n",
    "ADD COLUMN lineage TEXT,\n",
    "ADD COLUMN datasource VARCHAR;        \n",
    "         \"\"\")\n",
    "\n",
    "print (query_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "################ update columns:\n",
    "print (\"B) update new columns:\")\n",
    "query_update_new_columns = (\"\"\"\n",
    "         \n",
    "UPDATE \"\"\"+schema+\".\"+name_of_table+\"\"\" \n",
    "SET\n",
    "city_code = urau_code,\n",
    "city_code_version ='ua_2021',\n",
    "parameter = '\"Urban Audit indicators - check estat code\"',\n",
    "parameter_value = pixel_count_norm ,\n",
    " parameter_id = 'city_clc2018_water_in_and_around',\n",
    " lineage   = 'Get land cover data from CLC 2018 in and around city, by creating a buffer around city geometry. This notebook focuses on Water classes (CLC4**): https://github.com/FAIRiCUBE/uc1-urban-climate/blob/master/notebooks/dev/f02_cube/subcubes_CLC2018_400.ipynb',\n",
    " datasource ='https://land.copernicus.eu/en/products/corine-land-cover';\n",
    "         \n",
    "            \n",
    "         \"\"\")\n",
    "print (query_update_new_columns)\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query_update_new_columns)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "print (\"update of table done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation ob table:\n",
      "end transformation\n"
     ]
    }
   ],
   "source": [
    "## (B)bring row to columns:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"c_city_era5_2m_temperature\" #ouput\n",
    "\n",
    "\n",
    "## open connection:\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "connection.commit()\n",
    "## testing reading tables from database:\n",
    "\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query_long_table = text(\"\"\"\n",
    "SELECT\n",
    "    city_code, \n",
    "    parameter_id, \n",
    "    parameter_value, \n",
    "    year, \n",
    "    city_code_version, \n",
    "    parameter, \n",
    "    lineage,\n",
    "    datasource                    \n",
    "    FROM cube.cu_city_era5_2m_temperature;\n",
    "    \"\"\")\n",
    "    df_wide_table = pd.read_sql_query(query_long_table, conn)\n",
    "    \n",
    "    \n",
    "#print (df_wide_table)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Transformation ob table:\")\n",
    "\n",
    "\n",
    "res = df_wide_table.pivot_table(index=[\n",
    "              'city_code', \n",
    "            'parameter_id', \n",
    "            'city_code_version', \n",
    "            'parameter', \n",
    "            'lineage', \n",
    "            'datasource'          \n",
    "        ]    \n",
    ", columns='year',\n",
    "                     values='parameter_value', aggfunc='first').reset_index()\n",
    "\n",
    "\n",
    "###################################################\n",
    "name_of_table = name_of_table\n",
    "export_df_to_sql = res  # dataframe to be exported#\n",
    "schmema_name = schema\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "print (\"end transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation ob table:\n",
      "     city_code city_code_version   parameter_id  \\\n",
      "0       FR022C           ua_2021  city_imp_2018   \n",
      "1       IT049C           ua_2021  city_imp_2018   \n",
      "2       SE014C           ua_2021  city_imp_2018   \n",
      "3       LT006C           ua_2021  city_imp_2018   \n",
      "4       ES043C           ua_2021  city_imp_2018   \n",
      "...        ...               ...            ...   \n",
      "1443    ES019C           ua_2021  city_imp_2018   \n",
      "1444    RO020C           ua_2021  city_imp_2018   \n",
      "1445    NL014C           ua_2021  city_imp_2018   \n",
      "1446    IT043C           ua_2021  city_imp_2018   \n",
      "1447    SE012C           ua_2021  city_imp_2018   \n",
      "\n",
      "                                         parameter  \\\n",
      "0     HRL Imperviousness 2018 [ha] inside the city   \n",
      "1     HRL Imperviousness 2018 [ha] inside the city   \n",
      "2     HRL Imperviousness 2018 [ha] inside the city   \n",
      "3     HRL Imperviousness 2018 [ha] inside the city   \n",
      "4     HRL Imperviousness 2018 [ha] inside the city   \n",
      "...                                            ...   \n",
      "1443  HRL Imperviousness 2018 [ha] inside the city   \n",
      "1444  HRL Imperviousness 2018 [ha] inside the city   \n",
      "1445  HRL Imperviousness 2018 [ha] inside the city   \n",
      "1446  HRL Imperviousness 2018 [ha] inside the city   \n",
      "1447  HRL Imperviousness 2018 [ha] inside the city   \n",
      "\n",
      "                                                lineage  \\\n",
      "0     https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "1     https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "2     https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "3     https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "4     https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "...                                                 ...   \n",
      "1443  https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "1444  https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "1445  https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "1446  https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "1447  https://sdi.eea.europa.eu/catalogue/srv/eng/ca...   \n",
      "\n",
      "                                             datasource             year  \\\n",
      "0     https://land.copernicus.eu/en/products/high-re...  imp2018_area_ha   \n",
      "1     https://land.copernicus.eu/en/products/high-re...  imp2018_area_ha   \n",
      "2     https://land.copernicus.eu/en/products/high-re...  imp2018_area_ha   \n",
      "3     https://land.copernicus.eu/en/products/high-re...  imp2018_area_ha   \n",
      "4     https://land.copernicus.eu/en/products/high-re...  imp2018_area_ha   \n",
      "...                                                 ...              ...   \n",
      "1443  https://land.copernicus.eu/en/products/high-re...  parameter_value   \n",
      "1444  https://land.copernicus.eu/en/products/high-re...  parameter_value   \n",
      "1445  https://land.copernicus.eu/en/products/high-re...  parameter_value   \n",
      "1446  https://land.copernicus.eu/en/products/high-re...  parameter_value   \n",
      "1447  https://land.copernicus.eu/en/products/high-re...  parameter_value   \n",
      "\n",
      "      parameter_value  \n",
      "0           4092.6243  \n",
      "1            691.3909  \n",
      "2           2110.9868  \n",
      "3           1407.3721  \n",
      "4            925.4147  \n",
      "...               ...  \n",
      "1443        4128.2687  \n",
      "1444         412.2846  \n",
      "1445        4726.9006  \n",
      "1446        1315.1937  \n",
      "1447        3530.7521  \n",
      "\n",
      "[1448 rows x 8 columns]\n",
      "dataframe to sql:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ManuelLÃ¶hnertz\\AppData\\Local\\Temp\\ipykernel_5856\\708495879.py:33: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  df_transformed_table =df_wide_table.melt(id_vars=[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end transformation\n"
     ]
    }
   ],
   "source": [
    "## (A) bring  volumns to rows::\n",
    "## bring sql table to data frame:\n",
    "\n",
    "schema = \"cube\"\n",
    "name_of_table = \"cu_city_hrl_imperviousness_2018\" \n",
    "\n",
    "\n",
    "## open connection:\n",
    "connection = engine_postgresql.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "connection.commit()\n",
    "## testing reading tables from database:\n",
    "\n",
    "with engine_postgresql.begin() as conn:\n",
    "    query_wide_table = text(\"\"\"\n",
    "   SELECT city_code, imp2018_area_ha, city_code_version, parameter, parameter_id, parameter_value, lineage, datasource\n",
    "\tFROM cube.c_city_hrl_imperviousness_2018;\n",
    "    \n",
    "    \n",
    "    \"\"\")\n",
    "    df_wide_table = pd.read_sql_query(query_wide_table, conn)\n",
    "    \n",
    "    \n",
    "#print (df_wide_table)\n",
    "\n",
    "\n",
    "\n",
    "print (\"Transformation ob table:\")\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "df_transformed_table =df_wide_table.melt(id_vars=[\n",
    "                    'city_code', \n",
    "                    'city_code_version', \n",
    "                    'parameter_id', \n",
    "                    'parameter', \n",
    "                    'lineage', \n",
    "                    'datasource'\n",
    "                        ], var_name=\"year\", value_name=\"parameter_value\")\n",
    "\n",
    "\n",
    "\n",
    "print(df_transformed_table)\n",
    "\n",
    "\n",
    "\n",
    "print (\"dataframe to sql:\")\n",
    "\n",
    "\n",
    "###################################################\n",
    "#name_of_table = name_of_table\n",
    "export_df_to_sql = df_transformed_table  # dataframe to be exported\n",
    "schmema_name = schema\n",
    "###################################################\n",
    "export_df_to_sql.to_sql(name_of_table, engine_postgresql,  schema=schmema_name,if_exists='replace')\n",
    "print (\"end transformation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
